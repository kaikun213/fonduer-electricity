{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract electricity prices and volume from VENRON data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook we use `Fonduer` to extract relations from the `VENRON` dataset.  \n",
    "This code is a modified version of their original hardware [tutorial](https://github.com/HazyResearch/fonduer-tutorials/tree/master/hardware).  \n",
    "The `Fonduer` pipeline (as outlined in the [paper](https://arxiv.org/abs/1703.05028)), and the iterative KBC process:\n",
    "\n",
    "1. KBC Initialization\n",
    "2. Candidate Generation and Multimodal Featurization\n",
    "3. Probabilistic Relation Classification\n",
    "4. Error Analysis and Iterative KBC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First we import the relevant libraries and connect to the local database.  \n",
    "Follow the README instructions to setup the connection to the postgres DB correctly.\n",
    "\n",
    "If the database has existing candidates with generated features, the will not be overriden.  \n",
    "To re-run the entire pipeline including initialization drop the database first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! dropdb -h postgres -h postgres -h postgres -h postgres -h postgres -h postgres -h postgres -h postgres --if-exists elec_price_vol\n",
    "! createdb -h postgres -h postgres -h postgres -h postgres -h postgres -h postgres -h postgres -h postgres elec_price_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PARALLEL = 8 # 4  # assuming a quad-core machine\n",
    "ATTRIBUTE = \"elec_price_vol\"\n",
    "DB_USERNAME = 'user'\n",
    "DB_PASSWORD = 'venron'\n",
    "conn_string = f'postgresql://{DB_USERNAME}:{DB_PASSWORD}@postgres:5432/{ATTRIBUTE}'\n",
    "    \n",
    "docs_path = 'data/gold/html/'\n",
    "pdf_path = 'data/gold/pdf/'\n",
    "gold_file = 'data/electricity_gold.csv'\n",
    "max_docs = 50 # 114\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Parsing and Transforming the Input Documents into Unified Data Models\n",
    "\n",
    "We first initialize a `Meta` object, which manages the connection to the database automatically, and enables us to save intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from fonduer import Meta, init_logging\n",
    "\n",
    "# Configure logging for Fonduer\n",
    "init_logging(log_dir=\"logs\")\n",
    "\n",
    "session = Meta.init(conn_string).Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from fonduer.parser.preprocessors import HTMLDocPreprocessor\n",
    "from fonduer.parser.models import Document, Sentence\n",
    "from fonduer.parser import Parser\n",
    "\n",
    "has_documents = session.query(Document).count() > 0\n",
    "\n",
    "corpus_parser = Parser(session, structural=True, lingual=True, visual=True, pdf_path=pdf_path)\n",
    "\n",
    "if (not has_documents): \n",
    "    doc_preprocessor = HTMLDocPreprocessor(docs_path, max_docs=max_docs)\n",
    "    %time corpus_parser.apply(doc_preprocessor, parallelism=PARALLEL)\n",
    "    \n",
    "print(f\"Documents: {session.query(Document).count()}\")\n",
    "print(f\"Sentences: {session.query(Sentence).count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Dividing the Corpus into Test and Train\n",
    "\n",
    "We'll split the documents 80/10/10 into train/dev/test splits. Note that here we do this in a non-random order to preserve the consistency and we reference the splits by 0/1/2 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "ld   = len(docs)\n",
    "\n",
    "train_docs = set()\n",
    "dev_docs   = set()\n",
    "test_docs  = set()\n",
    "splits = (0.8, 0.9)\n",
    "data = [(doc.name, doc) for doc in docs]\n",
    "data.sort(key=lambda x: x[0])\n",
    "for i, (doc_name, doc) in enumerate(data):\n",
    "    if i < splits[0] * ld:\n",
    "        train_docs.add(doc)\n",
    "    elif i < splits[1] * ld:\n",
    "        dev_docs.add(doc)\n",
    "    else:\n",
    "        test_docs.add(doc)\n",
    "from pprint import pprint\n",
    "pprint([x.name for x in train_docs][0:5])\n",
    "print(f\"Number of documents split: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Mention Extraction, Candidate Extraction Multimodal Featurization\n",
    "\n",
    "Given the unified data model from Phase 1, `Fonduer` extracts relation\n",
    "candidates based on user-provided **matchers** and **throttlers**. Then,\n",
    "`Fonduer` leverages the multimodality information captured in the unified data\n",
    "model to provide multimodal features for each candidate.\n",
    "\n",
    "## 2.1 Mention Extraction & Candidate Generation\n",
    "\n",
    "1. Define mention classes\n",
    "2. Use matcher functions to define the format of potential mentions\n",
    "3. Define Mentionspaces (Ngrams)\n",
    "4. Run Mention extraction (all possible ngrams in the document, API [ReadTheDocs](https://fonduer.readthedocs.io/en/stable/user/candidates.html#fonduer.candidates.MentionExtractor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates.models.temporary_context import TemporaryContext\n",
    "from fonduer.candidates import MentionNgrams, MentionDocuments, MentionFigures\n",
    "from typing import Collection, Optional, Iterator\n",
    "\n",
    "class StationMentionSpace(MentionNgrams):\n",
    "    \"\"\"Defines the **space** of Mentions.\n",
    "\n",
    "    Defines the space of Mentions as all n-grams (n_min <= n <= n_max) in a\n",
    "    Document *x*, divided into Sentences inside of html elements (such as table\n",
    "    cells).\n",
    "\n",
    "    :param n_min: Lower limit for the generated n_grams.\n",
    "    :type n_min: int\n",
    "    :param n_max: Upper limit for the generated n_grams.\n",
    "    :type n_max: int\n",
    "    :param split_tokens: Tokens, on which unigrams are split into two separate\n",
    "        unigrams.\n",
    "    :type split_tokens: tuple, list of str.\n",
    "    :param types: If specified, only yield TemporaryFigureMentions whose url ends in\n",
    "        one of the specified types. Example: types=[\"png\", \"jpg\", \"jpeg\"].\n",
    "    :type types: list, tuple of str\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, n_min: int = 1, n_max: int = 5, split_tokens: Collection[str] = [], types: Optional[str] = None\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize MentionNgrams.\"\"\"\n",
    "        MentionNgrams.__init__(self, n_min=n_min, n_max=n_max, split_tokens=split_tokens)\n",
    "        if types is not None:\n",
    "            self.types = [t.strip().lower() for t in types]\n",
    "        else:\n",
    "            self.types = None\n",
    "\n",
    "    def apply(self, doc: Document) -> Iterator[TemporaryContext]:\n",
    "        \"\"\"Generate MentionNgrams from a Document by parsing all of its Sentences.\n",
    "\n",
    "        :param doc: The ``Document`` to parse.\n",
    "        :type doc: ``Document``\n",
    "        :raises TypeError: If the input doc is not of type ``Document``.\n",
    "        \"\"\"\n",
    "        if not isinstance(doc, Document):\n",
    "            raise TypeError(\n",
    "                \"Input Contexts to MentionNgrams.apply() must be of type Document\"\n",
    "            )\n",
    "\n",
    "        for ts in MentionNgrams.apply(self, doc):\n",
    "            yield ts\n",
    "            \n",
    "        for ts in MentionDocuments.apply(self, doc):\n",
    "            yield ts\n",
    "            \n",
    "        for ts in MentionFigures.apply(self, doc):\n",
    "            yield ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates.models.document_mention import TemporaryDocumentMention\n",
    "from fonduer.candidates.models.figure_mention import TemporaryFigureMention\n",
    "from fonduer.candidates.models.span_mention import TemporarySpanMention\n",
    "from fonduer.candidates.matchers import RegexMatchSpan\n",
    "\n",
    "class RegexMatchFull(RegexMatchSpan):\n",
    "    \"\"\"Matches regex pattern on **full concatenated span, document-name and figure-urls**.\n",
    "\n",
    "    :param rgx: The RegEx pattern to use.\n",
    "    :type rgx: str\n",
    "    :param ignore_case: Whether or not to ignore case in the RegEx. Default\n",
    "        True.\n",
    "    :type ignore_case: bool\n",
    "    :param search: If True, *search* the regex pattern through the concatenated span.\n",
    "        If False, try to *match* the regex patten only at its beginning. Default False.\n",
    "    :type search: bool\n",
    "    :param full_match: If True, wrap the provided rgx with ``(<rgx>)$``.\n",
    "        Default True.\n",
    "    :type full_match: bool\n",
    "    :param longest_match_only: If True, only return the longest match. Default True.\n",
    "        Will be overridden by the parent matcher like :class:`Union` when it is wrapped\n",
    "        by :class:`Union`, :class:`Intersect`, or :class:`Inverse`.\n",
    "    :type longest_match_only: bool\n",
    "    \"\"\"\n",
    "\n",
    "    def _f(self, m: TemporaryContext) -> bool:\n",
    "        \"\"\"The internal (non-composed) version of filter function f\"\"\"\n",
    "        \n",
    "        def apply_rgx(attrib_span):\n",
    "            # search for string as e.g. \"_\" split operator is used\n",
    "            return (\n",
    "                True\n",
    "                if self.r.search(attrib_span)\n",
    "                is not None\n",
    "                else False\n",
    "            )\n",
    "        if isinstance(m, TemporarySpanMention):\n",
    "            return RegexMatchSpan._f(self, m)\n",
    "        if isinstance(m, TemporaryFigureMention):\n",
    "            return apply_rgx(m.figure.url)\n",
    "        if isinstance(m, TemporaryDocumentMention):\n",
    "            return apply_rgx(m.document.name)\n",
    "        \n",
    "        raise ValueError(\n",
    "            f\"\"\"\n",
    "            {self.__class__.__name__} only supports \n",
    "            TemporarySpanMention, TemporaryFigureMention and TemporaryDocumentMention\n",
    "            \"\"\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates.models import mention_subclass\n",
    "from fonduer.candidates.matchers import RegexMatchSpan\n",
    "from fonduer.candidates import MentionNgrams\n",
    "from fonduer.candidates import MentionExtractor \n",
    "from fonduer.candidates.models import Mention\n",
    "\n",
    "hasMentions = session.query(Mention).count() > 0\n",
    "\n",
    "# 1.) Mention subclasses\n",
    "Station = mention_subclass(\"Station\")\n",
    "Price = mention_subclass(\"Price\")\n",
    "\n",
    "### Dictionary of known stations ###\n",
    "stations = [\n",
    "    [\n",
    "        \"cob\",\n",
    "        \"california-oregon border\",\n",
    "        \"california-oregon border (cob)\",\n",
    "    ],\n",
    "    [\n",
    "        \"palo verde\",\n",
    "        \"palo\",\n",
    "    ],\n",
    "    [\n",
    "        \"mid columbia\",\n",
    "        \"mid-columbia\",\n",
    "        \"midc\",\n",
    "        \"mid-c\",\n",
    "    ],\n",
    "    [\n",
    "        \"mead\",\n",
    "        \"meadmktplace\",\n",
    "        \"mead/marketplace\",\n",
    "    ],\n",
    "    [\n",
    "        \"np-15\",\n",
    "        \"np 15\",\n",
    "        \"np%2015\",\n",
    "        \"california northern zone\",\n",
    "        \"california northern zone (np-15)\",\n",
    "    ],\n",
    "    [\n",
    "        \"sp-15\",\n",
    "        \"sp 15\",\n",
    "        \"sp%2015\",\n",
    "        \"california southern zone\",\n",
    "        \"california southern zone (sp-15)\",\n",
    "    ],\n",
    "    [\n",
    "        \"pjm â€“ western hub\",\n",
    "        \"pjm\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "stations_mapping_dict = { k:station_list for station_list in stations for k in station_list }\n",
    "stations_list = [s for station_list in stations for s in station_list]\n",
    "\n",
    "if (not hasMentions):\n",
    "\n",
    "    # 2.) Matcher functions\n",
    "    station_rgx = '|'.join(stations_list)\n",
    "    station_matcher = RegexMatchFull(rgx=station_rgx)\n",
    "    price_matcher = RegexMatchSpan(rgx=r\"\\d{1,4}(\\.\\d{1,5})\", longest_match_only=True)\n",
    "\n",
    "    # 3.) Mention spaces (Ngrams)\n",
    "    station_ngrams = StationMentionSpace(n_max=4)\n",
    "    price_ngrams = MentionNgrams(n_max=1)\n",
    "\n",
    "\n",
    "    # 4.) Mention extraction\n",
    "    mention_extractor = MentionExtractor(\n",
    "        session, [Station, Price], [station_ngrams, price_ngrams], [station_matcher, price_matcher]\n",
    "    )\n",
    "    docs = session.query(Document).order_by(Document.name).all()\n",
    "    mention_extractor.apply(docs, parallelism=PARALLEL)\n",
    "\n",
    "    \n",
    "print(f\"Total Mentions: {session.query(Mention).count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.2 Candidate Extraction\n",
    "\n",
    "1. Define Candidate Class\n",
    "2. Define trottlers to reduce the number of possible candidates\n",
    "3. Extract candidates (View the API for the CandidateExtractor on [ReadTheDocs](https://fonduer.readthedocs.io/en/stable/user/candidates.html#fonduer.candidates.MentionExtractor).)\n",
    "\n",
    "In the last part we specified that these `Candidates` belong to the training set by specifying `split=0`; recall that we're referring to train/dev/test as splits 0/1/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.utils.data_model_utils import *\n",
    "import re\n",
    "from fonduer.candidates import CandidateExtractor\n",
    "from fonduer.candidates.models import candidate_subclass\n",
    "from fonduer.utils.visualizer import Visualizer\n",
    "\n",
    "\n",
    "# 1.) Define Candidate class\n",
    "StationPrice = candidate_subclass(\"StationPrice\", [Station, Price])\n",
    "\n",
    "has_candidates = session.query(StationPrice).filter(StationPrice.split == 0).count() > 0\n",
    "\n",
    "# 2.) DefineThrottlers\n",
    "def any_filter(c):\n",
    "    (station, price) = c\n",
    "    if 'volume' in get_aligned_ngrams(price, lower=True):\n",
    "        return False\n",
    "    if 'date' in get_aligned_ngrams(price, lower=True):\n",
    "        return False \n",
    "    if 'non' in get_aligned_ngrams(price, lower=True):\n",
    "        return False \n",
    "    return True\n",
    "\n",
    "any_throttler = any_filter\n",
    "\n",
    "# 3.) Candidate extraction\n",
    "candidate_extractor = CandidateExtractor(session, [StationPrice], throttlers=[any_throttler])\n",
    "\n",
    "for i, docs in enumerate([train_docs, dev_docs, test_docs]):\n",
    "    if (not has_candidates):\n",
    "        candidate_extractor.apply(docs, split=i, parallelism=PARALLEL)\n",
    "    print(f\"Number of Candidates in split={i}: {session.query(StationPrice).filter(StationPrice.split == i).count()}\")\n",
    "\n",
    "train_cands = candidate_extractor.get_candidates(split = 0)\n",
    "dev_cands = candidate_extractor.get_candidates(split = 1)\n",
    "test_cands = candidate_extractor.get_candidates(split = 2)\n",
    "\n",
    "\n",
    "# 4.) Visualize some candidate for error analysis\n",
    "pprint(train_cands[0][2003])\n",
    "vis = Visualizer(pdf_path)\n",
    "\n",
    "# Display a candidate\n",
    "vis.display_candidates([train_cands[0][2003]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.2 Multimodal Featurization\n",
    "Unlike dealing with plain unstructured text, `Fonduer` deals with richly formatted data, and consequently featurizes each candidate with a baseline library of multimodal features. \n",
    "\n",
    "### Featurize with `Fonduer`'s optimized Postgres Featurizer\n",
    "We now annotate the candidates in our training, dev, and test sets with features. The `Featurizer` provided by `Fonduer` allows this to be done in parallel to improve performance.\n",
    "\n",
    "View the API provided by the `Featurizer` on [ReadTheDocs](https://fonduer.readthedocs.io/en/stable/user/features.html#fonduer.features.Featurizer).\n",
    "\n",
    "At the end of this phase, `Fonduer` has generated the set of candidates and the feature matrix. Note that Phase 1 and 2 are relatively static and typically are only executed once during the KBC process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fonduer.features import Featurizer\n",
    "from fonduer.features.models import Feature\n",
    "\n",
    "featurizer = Featurizer(session, [StationPrice])\n",
    "\n",
    "has_features = session.query(Feature).count() > 0\n",
    "\n",
    "if (not has_features):\n",
    "    # Training set\n",
    "    %time featurizer.apply(split=0, train=True, parallelism=PARALLEL)\n",
    "    %time F_train = featurizer.get_feature_matrices(train_cands)\n",
    "    print(F_train[0].shape)\n",
    "\n",
    "    # Dev set\n",
    "    %time featurizer.apply(split=1, parallelism=PARALLEL)\n",
    "    %time F_dev = featurizer.get_feature_matrices(dev_cands)\n",
    "    print(F_dev[0].shape)\n",
    "\n",
    "    # Test set\n",
    "    %time featurizer.apply(split=2, parallelism=PARALLEL)\n",
    "    %time F_test = featurizer.get_feature_matrices(test_cands)\n",
    "    print(F_test[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Phase 3: Probabilistic Relation Classification\n",
    "In this phase, `Fonduer` applies user-defined **labeling functions**, which express various heuristics, patterns, and [weak supervision](http://hazyresearch.github.io/snorkel/blog/weak_supervision.html) strategies to label our data, to each of the candidates to create a label matrix that is used by our data programming engine.\n",
    "\n",
    "1. Load Gold Data\n",
    "\n",
    "--- \n",
    "\n",
    "Iterate the following steps\n",
    "\n",
    "2. Create labeling functions\n",
    "3. Apply labeling functions and measure accuracy of each LF (based on gold data).\n",
    "4. Build a generative model by combining the labeling functions\n",
    "5. Iterate on labeling function based on the models score\n",
    "\n",
    "---\n",
    "\n",
    "6. Finally build a descriminative model and test on the test set\n",
    "\n",
    "### 3.1) Loading Gold LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fonduer.supervision.models import GoldLabel\n",
    "from electricity_utils import get_gold_func\n",
    "from fonduer.supervision import Labeler\n",
    "\n",
    "# 1.) Load the gold data\n",
    "gold = get_gold_func(gold_file, attribute=ATTRIBUTE, stations_mapping_dict=stations_mapping_dict)\n",
    "docs = corpus_parser.get_documents()\n",
    "labeler = Labeler(session, [StationPrice])\n",
    "%time labeler.apply(docs=docs, lfs=[[gold]], table=GoldLabel, train=True, parallelism=PARALLEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2) Creating Labeling Functions\n",
    "\n",
    "We have 3 states that we can return from a LF: `ABSTAIN`, `FALSE` or `TRUE`.\n",
    "\n",
    "A library of data model utilities\n",
    "which can be used to write labeling functions are outline in [Read the\n",
    "Docs](http://fonduer.readthedocs.io/en/stable/user/data_model_utils.html). \n",
    "\n",
    "### 3.3) Applying the Labeling Functions\n",
    "\n",
    "Next, we need to actually run the LFs over all of our training candidates, producing a set of `Labels` and `LabelKeys` (just the names of the LFs) in the database. Note that this will delete any existing `Labels` and `LabelKeys` for this candidate set.\n",
    "\n",
    "View the API provided by the `Labeler` on [ReadTheDocs](https://fonduer.readthedocs.io/en/stable/user/supervision.html#fonduer.supervision.Labeler).\n",
    "\n",
    "We can also view statistics about the resulting label matrix.\n",
    "* **Coverage** is the fraction of candidates that the labeling function emits a non-zero label for.\n",
    "* **Overlap** is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a non-zero label for.\n",
    "* **Conflict** is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a conflicting non-zero label for.\n",
    "\n",
    "In addition, because we have already loaded the gold labels, we can view the emperical accuracy of these labeling functions when compared to our gold labels using the `analysis` module of [Snorkel](https://github.com/snorkel-team/snorkel)\n",
    "\n",
    "### 3.4) Build Generative Model\n",
    "\n",
    "Now, we'll train a model of the LFs to estimate their accuracies. Once the model is trained, we can combine the outputs of the LFs into a single, noise-aware training label set for our extractor. Intuitively, we'll model the LFs by observing how they overlap and conflict with each other. To do so, we use [Snorkel](https://github.com/snorkel-team/snorkel)'s single-task label model.\n",
    "\n",
    "We then print out the marginal probabilities for each training candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "from fonduer.parser.models.sentence import Sentence\n",
    "from fonduer.parser.models.table import Cell\n",
    "\n",
    "def _min_range_diff(\n",
    "    a_start: int, a_end: int, b_start: int, b_end: int, absolute: bool = True\n",
    ") -> int:\n",
    "    # if absolute=True, return the absolute value of minimum magnitude difference\n",
    "    # if absolute=False, return the raw value of minimum magnitude difference\n",
    "    # TODO: move back to efficient implementation once it sees that\n",
    "    # min_range_diff(3,3,2,3) = 0 return max(0, max(a_end - b_start, b_end -\n",
    "    # a_start))\n",
    "    f = lambda x: (abs(x) if absolute else x)\n",
    "    return min(\n",
    "        [\n",
    "            f(ii[0] - ii[1])\n",
    "            for ii in itertools.product(\n",
    "                list(range(a_start, a_end + 1)), list(range(b_start, b_end + 1))\n",
    "            )\n",
    "        ],\n",
    "        key=abs\n",
    "    )\n",
    "\n",
    "\n",
    "def min_row_diff(\n",
    "    a: Union[Cell, Sentence], b: Union[Cell, Sentence], absolute: bool = True\n",
    ") -> int:\n",
    "    return _min_range_diff(\n",
    "        a.row_start, a.row_end, b.row_start, b.row_end, absolute=absolute\n",
    "    )\n",
    "\n",
    "\n",
    "def min_col_diff(\n",
    "    a: Union[Cell, Sentence], b: Union[Sentence, Cell], absolute: bool = True\n",
    ") -> int:\n",
    "    return _min_range_diff(\n",
    "        a.col_start, a.col_end, b.col_start, b.col_end, absolute=absolute\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates.models.span_mention import TemporarySpanMention\n",
    "from fonduer.candidates.models import Candidate, Mention\n",
    "from typing import Iterator, Tuple, Union\n",
    "from fonduer.utils.data_model_utils.tabular import _get_aligned_sentences\n",
    "from fonduer.utils.utils_table import is_axis_aligned # min_col_diff, min_row_diff, \n",
    "from fonduer.utils.utils import tokens_to_ngrams\n",
    "from fonduer.utils.data_model_utils.utils import _to_span, _to_spans\n",
    "from itertools import chain\n",
    "\n",
    "def get_neighbor_cell_ngrams_own(\n",
    "    mention: Union[Candidate, Mention, TemporarySpanMention],\n",
    "    dist: int = 1,\n",
    "    directions: bool = False,\n",
    "    attrib: str = \"words\",\n",
    "    n_min: int = 1,\n",
    "    n_max: int = 1,\n",
    "    lower: bool = True,\n",
    "    absolute: bool = False,\n",
    ") -> Iterator[Union[str, Tuple[str, str]]]:\n",
    "    \"\"\"\n",
    "    Get the ngrams from all Cells that are within a given Cell distance in one\n",
    "    direction from the given Mention.\n",
    "\n",
    "    Note that if a candidate is passed in, all of its Mentions will be\n",
    "    searched. If `directions=True``, each ngram will be returned with a\n",
    "    direction in {'UP', 'DOWN', 'LEFT', 'RIGHT'}.\n",
    "\n",
    "    :param mention: The Mention whose neighbor Cells are being searched\n",
    "    :param dist: The Cell distance within which a neighbor Cell must be to be\n",
    "        considered\n",
    "    :param directions: A Boolean expressing whether or not to return the\n",
    "        direction of each ngram\n",
    "    :param attrib: The token attribute type (e.g. words, lemmas, poses)\n",
    "    :param n_min: The minimum n of the ngrams that should be returned\n",
    "    :param n_max: The maximum n of the ngrams that should be returned\n",
    "    :param lower: If True, all ngrams will be returned in lower case\n",
    "    :rtype: a *generator* of ngrams (or (ngram, direction) tuples if directions=True)\n",
    "    \"\"\"\n",
    "    # TODO: Fix this to be more efficient (optimize with SQL query)\n",
    "    spans = _to_spans(mention)\n",
    "    for span in spans:\n",
    "        for ngram in get_sentence_ngrams(\n",
    "            span, attrib=attrib, n_min=n_min, n_max=n_max, lower=lower\n",
    "        ):\n",
    "            yield ngram\n",
    "        if span.sentence.is_tabular():\n",
    "            root_cell = span.sentence.cell\n",
    "            for sentence in chain.from_iterable(\n",
    "                [\n",
    "                    _get_aligned_sentences(root_cell, \"row\"),\n",
    "                    _get_aligned_sentences(root_cell, \"col\"),\n",
    "                ]\n",
    "            ):\n",
    "                \n",
    "                #####################################################################\n",
    "\n",
    "                # Fix absolute bug. Because the underlying min_range_diff function \n",
    "                # will take negative numbers (e.g. -2), even though 0 would be closer\n",
    "                row_diff = min_row_diff(sentence, root_cell, absolute=False)\n",
    "                col_diff = min_col_diff(sentence, root_cell, absolute=False)\n",
    "                    \n",
    "                if (\n",
    "                    (row_diff or col_diff)\n",
    "                    and not (row_diff and col_diff)\n",
    "                    and abs(row_diff) + abs(col_diff) <= dist\n",
    "                ):\n",
    "                    if directions:\n",
    "                        direction = \"\"\n",
    "                        if col_diff == 0:\n",
    "                            if 0 < row_diff and row_diff <= dist:\n",
    "                                direction = \"UP\"\n",
    "                            elif 0 > row_diff and row_diff >= -dist:\n",
    "                                direction = \"DOWN\"\n",
    "                        elif row_diff == 0:\n",
    "                            if 0 < col_diff and col_diff <= dist:\n",
    "                                direction = \"RIGHT\"\n",
    "                            elif 0 > col_diff and col_diff >= -dist:\n",
    "                                direction = \"LEFT\"\n",
    "                        for ngram in tokens_to_ngrams(\n",
    "                            getattr(sentence, attrib),\n",
    "                            n_min=n_min,\n",
    "                            n_max=n_max,\n",
    "                            lower=lower,\n",
    "                        ):\n",
    "                            yield (ngram, direction)\n",
    "                    else:\n",
    "                        for ngram in tokens_to_ngrams(\n",
    "                            getattr(sentence, attrib),\n",
    "                            n_min=n_min,\n",
    "                            n_max=n_max,\n",
    "                            lower=lower,\n",
    "                        ):\n",
    "                            yield ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to check applied labelling functions\n",
    "from fonduer.supervision.models import Label\n",
    "from sqlalchemy import func\n",
    "\n",
    "def get_applied_lfs(): \n",
    "    labels = session.query(Label).all()\n",
    "    ls = [x for x in labels if len(x.values) > 0]\n",
    "    lfs = [lf for l in ls for lf in l.keys]\n",
    "    return set(lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.utils.data_model_utils import *\n",
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "ABSTAIN = -1\n",
    "FALSE = 0\n",
    "TRUE = 1\n",
    "\n",
    "@labeling_function()\n",
    "def LF_other_station_table(c):\n",
    "    station_span = c.station.context.get_span().lower()\n",
    "    neighbour_cells = get_neighbor_cell_ngrams_own(c.price, dist=100, directions=True, n_max = 4, absolute = True)\n",
    "    up_cells = [x for x in neighbour_cells if len(x) > 1 and x[1] == 'DOWN' and x[0] in stations_list]\n",
    "    # No station name in upper cells\n",
    "    if (len(up_cells) == 0):\n",
    "        return ABSTAIN\n",
    "    # Check if the next upper aligned station-span corresponds to the candidate span (or equivalents)\n",
    "    closest_header = up_cells[len(up_cells)-1]\n",
    "    return TRUE if closest_header[0] in stations_mapping_dict[station_span] else FALSE\n",
    "\n",
    "@labeling_function()\n",
    "def LF_station_non_meta_tag(c):\n",
    "    html_tags = get_ancestor_tag_names(c.station)\n",
    "    return FALSE if ('head' in html_tags and 'title' in html_tags) else ABSTAIN\n",
    "\n",
    "# Basic constraint for the price LFs to be true -> no wrong station (increase accuracy)\n",
    "def base(c):\n",
    "    return (\n",
    "        LF_station_non_meta_tag(c) != 0 and \n",
    "        LF_other_station_table(c) != 0 and \n",
    "        LF_off_peak_head(c) != 0 and\n",
    "        LF_purchases(c)\n",
    "    )\n",
    "\n",
    "# 2.) Create labeling functions \n",
    "@labeling_function()\n",
    "def LF_on_peak_head(c):\n",
    "    return TRUE if 'on peak' in get_aligned_ngrams(c.price, n_min=2, n_max=2)  and base(c) else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def LF_off_peak_head(c):\n",
    "    return FALSE if 'off peak' in get_aligned_ngrams(c.price, n_min=2, n_max=2) else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def LF_price_range(c):\n",
    "    price = float(c.price.context.get_span())\n",
    "    return TRUE if price > 0 and price < 1000 and base(c) else FALSE\n",
    "\n",
    "@labeling_function()\n",
    "def LF_price_head(c):\n",
    "    return TRUE if 'price' in get_aligned_ngrams(c.price) and base(c) else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def LF_firm_head(c):\n",
    "    return TRUE if 'firm' in get_aligned_ngrams(c.price)and base(c) else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def LF_dollar_to_left(c):\n",
    "    return TRUE if '$' in get_left_ngrams(c.price, window=2) and base(c) else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def LF_purchases(c):\n",
    "    return FALSE if 'purchases' in get_aligned_ngrams(c.price, n_min=1) else ABSTAIN\n",
    "\n",
    "station_price_lfs = [\n",
    "    LF_other_station_table,\n",
    "    LF_station_non_meta_tag,\n",
    "        \n",
    "    # indicator\n",
    "    LF_price_range,\n",
    "    \n",
    "    # negative indicators\n",
    "    LF_off_peak_head,\n",
    "    LF_purchases,\n",
    "    \n",
    "    # positive indicators\n",
    "    LF_on_peak_head,    \n",
    "    LF_price_head,\n",
    "    LF_firm_head,\n",
    "    LF_dollar_to_left,\n",
    "]\n",
    "\n",
    "# 3.) Apply the LFs on the training set\n",
    "labeler = Labeler(session, [StationPrice])\n",
    "%time labeler.apply(split=0, lfs=[station_price_lfs], train=True, clear=True, parallelism=PARALLEL)\n",
    "%time L_train = labeler.get_label_matrices(train_cands)\n",
    "\n",
    "# Check that LFs are all applied (avoid crash)\n",
    "applied_lfs = L_train[0].shape[1]\n",
    "has_non_applied = applied_lfs != len(station_price_lfs)\n",
    "print(f\"Labeling functions on train_cands not ABSTAIN: {applied_lfs} (/{len(station_price_lfs)})\")\n",
    "\n",
    "if (has_non_applied):\n",
    "    applied_lfs = get_applied_lfs()\n",
    "    non_applied_lfs = [l.name for l in station_price_lfs if l.name not in applied_lfs]\n",
    "    print(f\"Labling functions {non_applied_lfs} are not applied.\")\n",
    "    station_price_lfs = [l for l in station_price_lfs if l.name in applied_lfs]\n",
    "\n",
    "# 4.) Evaluate their accuracy\n",
    "L_gold_train = labeler.get_gold_labels(train_cands, annotator='gold')\n",
    "# Sort LFs for LFAnalysis because LFAnalysis does not sort LFs,\n",
    "# while columns of L_train are sorted alphabetically already.\n",
    "sorted_lfs = sorted(station_price_lfs, key=lambda lf: lf.name)\n",
    "LFAnalysis(L=L_train[0], lfs=sorted_lfs).lf_summary(Y=L_gold_train[0].reshape(-1))\n",
    "\n",
    "# 5.) Build generative model\n",
    "gen_model = LabelModel(cardinality=2)\n",
    "%time gen_model.fit(L_train[0], n_epochs=500, log_freq=100)\n",
    "\n",
    "train_marginals = gen_model.predict_proba(L_train[0])\n",
    "plt.hist(train_marginals[:, TRUE], bins=20)\n",
    "plt.show()\n",
    "\n",
    "# Apply on dev-set\n",
    "labeler.apply(split=1, lfs=[station_price_lfs], clear=True, parallelism=PARALLEL)\n",
    "%time L_dev = labeler.get_label_matrices(dev_cands)\n",
    "\n",
    "L_gold_dev = labeler.get_gold_labels(dev_cands, annotator='gold')\n",
    "LFAnalysis(L=L_dev[0], lfs=sorted_lfs).lf_summary(Y=L_gold_dev[0].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for analysis\n",
    "labels = session.query(Label).all()\n",
    "gold_labels = session.query(GoldLabel).all()\n",
    "gold_labels_map = { gold_label.candidate_id: gold_label for gold_label in gold_labels }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates.models import Candidate\n",
    "\n",
    "DB_FALSE = FALSE +1\n",
    "DB_ABSTAIN = ABSTAIN +1\n",
    "DB_TRUE = TRUE +1\n",
    "\n",
    "def get_incorrect_instances(lf):\n",
    "    def is_wrong_label(label):\n",
    "        if (lf.name not in label.keys):\n",
    "            return False # Abstain\n",
    "        assigned_label = label.values[label.keys.index(lf.name)]\n",
    "        gold_label = gold_labels_map[label.candidate_id] # [x for x in gold_labels if x.candidate_id == label.candidate_id][0]\n",
    "        return gold_label.values[0] != assigned_label\n",
    "    return [x.candidate for x in labels if is_wrong_label(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = station_price_lfs[5]\n",
    "wrong_cands = get_incorrect_instances(lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(f\"Labeling Function: {lf.name} has wrongly labelled the candidate(1/{len(wrong_cands)}):\")\n",
    "if (len(wrong_cands) > 0):\n",
    "    wrong_cand = wrong_cands[100]\n",
    "    pprint(wrong_cand)\n",
    "    pprint('LF is True' if lf(wrong_cand) == 1 else 'LF is False')\n",
    "    vis = Visualizer(pdf_path)\n",
    "\n",
    "    # Display a candidate\n",
    "    vis.display_candidates([wrong_cand])\n",
    "else:\n",
    "    print(\"There are no wrong candidates for this labeling function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Discriminative Model \n",
    "\n",
    "Fonduer uses the machine learning framework [Emmental](https://github.com/SenWu/emmental) to support all model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emmental\n",
    "\n",
    "# Setup training config\n",
    "config = {\n",
    "    \"meta_config\": {\"verbose\": True},\n",
    "    \"model_config\": {\"model_path\": None, \"device\": 0, \"dataparallel\": False},\n",
    "    \"learner_config\": {\n",
    "        \"n_epochs\": 50,\n",
    "        \"optimizer_config\": {\"lr\": 0.001, \"l2\": 0.0},\n",
    "        \"task_scheduler\": \"round_robin\",\n",
    "    },\n",
    "    \"logging_config\": {\n",
    "        \"evaluation_freq\": 1,\n",
    "        \"counter_unit\": \"epoch\",\n",
    "        \"checkpointing\": False,\n",
    "        \"checkpointer_config\": {\n",
    "            \"checkpoint_metric\": {f\"{ATTRIBUTE}/{ATTRIBUTE}/train/loss\": \"min\"},\n",
    "            \"checkpoint_freq\": 1,\n",
    "            \"checkpoint_runway\": 2,\n",
    "            \"clear_intermediate_checkpoints\": True,\n",
    "            \"clear_all_checkpoints\": True,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "emmental.init(Meta.log_path)\n",
    "emmental.Meta.update_config(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect word counter from training data\n",
    "from fonduer.learning.utils import collect_word_counter\n",
    "\n",
    "word_counter = collect_word_counter(train_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word embedding module for LSTM model\n",
    "# (in Logistic Regression, we generate it since Fonduer dataset requires word2id dict)\n",
    "from emmental.modules.embedding_module import EmbeddingModule\n",
    "\n",
    "arity = 2\n",
    "\n",
    "# Geneate special tokens\n",
    "specials = []\n",
    "for i in range(arity):\n",
    "    specials += [f\"~~[[{i}\", f\"{i}]]~~\"]\n",
    "\n",
    "emb_layer = EmbeddingModule(\n",
    "    word_counter=word_counter, word_dim=300, specials=specials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataloader for training set\n",
    "from emmental.data import EmmentalDataLoader\n",
    "from fonduer.learning.dataset import FonduerDataset\n",
    "import numpy as np\n",
    "\n",
    "# Filter out noise samples\n",
    "diffs = train_marginals.max(axis=1) - train_marginals.min(axis=1)\n",
    "train_idxs = np.where(diffs > 1e-6)[0]\n",
    "\n",
    "train_dataloader = EmmentalDataLoader(\n",
    "    task_to_label_dict={ATTRIBUTE: \"labels\"},\n",
    "    dataset=FonduerDataset(\n",
    "        ATTRIBUTE,\n",
    "        train_cands[0],\n",
    "        F_train[0],\n",
    "        emb_layer.word2id,\n",
    "        train_marginals,\n",
    "        train_idxs,\n",
    "    ),\n",
    "    split=\"train\",\n",
    "    batch_size=100,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emmental.model import EmmentalModel\n",
    "from fonduer.learning.task import create_task\n",
    "from emmental.learner import EmmentalLearner\n",
    "\n",
    "tasks = create_task(\n",
    "    ATTRIBUTE, 2, F_train[0].shape[1], 2, emb_layer, model=\"LogisticRegression\" # \"LSTM\" \n",
    ")\n",
    "\n",
    "model = EmmentalModel(name=f\"{ATTRIBUTE}_task\")\n",
    "\n",
    "for task in tasks:\n",
    "    model.add_task(task)\n",
    "\n",
    "emmental_learner = EmmentalLearner()\n",
    "emmental_learner.learn(model, [train_dataloader])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on the Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataloader for test data\n",
    "test_dataloader = EmmentalDataLoader(\n",
    "    task_to_label_dict={ATTRIBUTE: \"labels\"},\n",
    "    dataset=FonduerDataset(\n",
    "        ATTRIBUTE, test_cands[0], F_test[0], emb_layer.word2id, 2\n",
    "    ),\n",
    "    split=\"test\",\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import csv\n",
    "import re\n",
    "from builtins import range\n",
    "\n",
    "from fonduer.learning.utils import confusion_matrix\n",
    "from fonduer.supervision.models import GoldLabel, GoldLabelKey\n",
    "from fonduer.candidates.models import Candidate \n",
    "\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    if \"IPKernelApp\" not in get_ipython().config:\n",
    "        raise ImportError(\"console\")\n",
    "except (AttributeError, ImportError):\n",
    "    from tqdm import tqdm\n",
    "else:\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "# Define labels\n",
    "ABSTAIN = -1\n",
    "FALSE = 0\n",
    "TRUE = 1\n",
    "\n",
    "\n",
    "def get_gold_dict(\n",
    "    filename, doc_on=True, station_on=True, price_on=True, attribute=None, docs=None, stations_mapping_dict=None\n",
    "):\n",
    "    with codecs.open(filename, encoding=\"utf-8\") as csvfile:\n",
    "        gold_reader = csv.reader(csvfile)\n",
    "        gold_dict = set()\n",
    "        headers = next(gold_reader, None)  # skip the headers\n",
    "        for row in gold_reader:\n",
    "            if (row == headers):\n",
    "                continue\n",
    "            (folder, subfolder, doc, sheet, station, date, designation, price, volume) = row\n",
    "            if (docs is None or re.sub(\"\\.xls\", \"\", doc).upper() in docs) and designation == 'On Peak': # filter off peak labels\n",
    "                key = []\n",
    "                if doc_on:\n",
    "                    key.append(re.sub(\"\\.xls\", \"\", doc).upper())\n",
    "                if station_on:\n",
    "                    key.append(station.upper())\n",
    "                if price_on:\n",
    "                    key.append(re.sub(\"[^0-9.]\", \"\", price).upper())\n",
    "                gold_dict.add(tuple(key))\n",
    "    return gold_dict\n",
    "\n",
    "\n",
    "\n",
    "def get_gold_func(\n",
    "    gold_file, attribute, stations_mapping_dict=None\n",
    "): \n",
    "    gold_dict = get_gold_dict(\n",
    "        gold_file, \n",
    "        attribute=attribute, \n",
    "        stations_mapping_dict=stations_mapping_dict\n",
    "    )\n",
    "    def gold(c: Candidate) -> int:\n",
    "        doc = (c[0].context.sentence.document.name).upper()\n",
    "        station = (c[0].context.get_span()).upper()\n",
    "        price = (\"\".join(c[1].context.get_span().split())).upper()\n",
    "\n",
    "        stations = stations_mapping_dict[station.lower()] if stations_mapping_dict != None else [station]\n",
    "\n",
    "        # account for all station abbrevations, as we do not consider the entity-linking problem (same entity with multiple identity descriptors)\n",
    "        for station_abbr in stations:\n",
    "            if (doc, station_abbr.upper(), price) in gold_dict:\n",
    "                return TRUE\n",
    "        return FALSE\n",
    "    return gold\n",
    "\n",
    "def entity_level_f1(\n",
    "    candidates, gold_file, attribute=None, corpus=None, stations_mapping_dict=None\n",
    "):\n",
    "    \"\"\"Checks entity-level recall of candidates compared to gold.\n",
    "\n",
    "    Turns a CandidateSet into a normal set of entity-level tuples\n",
    "    (doc, part, [attribute_value])\n",
    "    then compares this to the entity-level tuples found in the gold.\n",
    "\n",
    "    Example Usage:\n",
    "        from electricity_utils import entity_level_f1\n",
    "        candidates = # CandidateSet of all candidates you want to consider\n",
    "        gold_file = 'tutorials/tables/data/electricity/electricity_gold.csv'\n",
    "        entity_level_f1(candidates, gold_file, 'elec_price_vol')\n",
    "    \"\"\"\n",
    "    docs = [(re.sub(\"Document \", \"\", doc.name)).upper() for doc in corpus] if corpus else None\n",
    "    price_on = attribute is not None\n",
    "    gold_set = get_gold_dict(\n",
    "        gold_file,\n",
    "        docs=docs,\n",
    "        doc_on=True,\n",
    "        station_on=True,\n",
    "        price_on=price_on,\n",
    "        attribute=attribute,\n",
    "        stations_mapping_dict=stations_mapping_dict\n",
    "    )\n",
    "    if len(gold_set) == 0:\n",
    "        print(f\"Gold File: {gold_file}\\n Attribute: {attribute}\")\n",
    "        print(\"Gold set is empty.\")\n",
    "        return\n",
    "    # Turn CandidateSet into set of tuples\n",
    "    print(\"Preparing candidates...\")\n",
    "    entities = set()\n",
    "    for i, c in enumerate(tqdm(candidates)):\n",
    "        station = c[0].context.get_span().upper()\n",
    "        doc = c[0].context.sentence.document.name.upper()\n",
    "        price = c[1].context.get_span()\n",
    "\n",
    "        # Account for all station abbrevations, as we do not consider the entity-linking problem (same entity with multiple identity descriptors)\n",
    "        # We only take the entity by the name how it is represented in the gold_dict\n",
    "        stations = stations_mapping_dict[station.lower()] if stations_mapping_dict != None else [station]\n",
    "        added_any = False\n",
    "        for station_abbr in stations:\n",
    "            if (doc, station_abbr.upper(), price) in gold_set:\n",
    "                entities.add((doc, station_abbr.upper(), price))\n",
    "                added_any = True\n",
    "        if (not added_any):\n",
    "            entities.add((doc, station, price))\n",
    "    \n",
    "    (TP_set, FP_set, FN_set) = confusion_matrix(entities, gold_set)\n",
    "    TP = len(TP_set)\n",
    "    FP = len(FP_set)\n",
    "    FN = len(FN_set)\n",
    "\n",
    "    prec = TP / (TP + FP) if TP + FP > 0 else float(\"nan\")\n",
    "    rec = TP / (TP + FN) if TP + FN > 0 else float(\"nan\")\n",
    "    f1 = 2 * (prec * rec) / (prec + rec) if prec + rec > 0 else float(\"nan\")\n",
    "    print(\"========================================\")\n",
    "    print(\"Scoring on Entity-Level Gold Data\")\n",
    "    print(\"========================================\")\n",
    "    print(f\"Corpus Precision {prec:.3}\")\n",
    "    print(f\"Corpus Recall    {rec:.3}\")\n",
    "    print(f\"Corpus F1        {f1:.3}\")\n",
    "    print(\"----------------------------------------\")\n",
    "    print(f\"TP: {TP} | FP: {FP} | FN: {FN}\")\n",
    "    print(\"========================================\\n\")\n",
    "    return [sorted(list(x)) for x in [TP_set, FP_set, FN_set]]\n",
    "\n",
    "def entity_to_candidates(entity, candidate_subset):\n",
    "    matches = []\n",
    "    for c in candidate_subset:\n",
    "        c_entity = tuple(\n",
    "            [c[0].context.sentence.document.name.upper()]\n",
    "            + [c[i].context.get_span().upper() for i in range(len(c))]\n",
    "        )\n",
    "        c_entity = tuple([str(x) for x in c_entity])\n",
    "        if c_entity == entity:\n",
    "            matches.append(c)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(test_dataloader, return_preds=True)\n",
    "positive = np.where(np.array(test_preds[\"probs\"][ATTRIBUTE])[:, TRUE] > 0.6)\n",
    "true_pred = [test_cands[0][_] for _ in positive[0]]\n",
    "%time (TP, FP, FN) = entity_level_f1(true_pred, gold_file, ATTRIBUTE, test_docs, stations_mapping_dict=stations_mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4: Error Analysis & Iterative KBC \n",
    "\n",
    "- Analyise the false positive (FP) and false negative (FN) candidates\n",
    "- Use the visualization tool to better understand which labeling functions might be responsible\n",
    "- Test the labeling functions on this candidates to verify they work as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from electricity_utils import entity_to_candidates\n",
    "\n",
    "def display_cand(cand_nr):\n",
    "    # Get a list of candidates that match the FN[10] entity\n",
    "    fp_cands = entity_to_candidates(FP[cand_nr], test_cands[0])\n",
    "\n",
    "    # Display a candidate\n",
    "    fp_cand = fp_cands[0]\n",
    "    print(fp_cand)\n",
    "    print(f\"Number of FP: {cand_nr}/{len(FP)}\")\n",
    "    vis.display_candidates([fp_cand])\n",
    "    return fp_cand\n",
    "    \n",
    "maximum = len(FP)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "from functools import partial\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "class Counter:\n",
    "    def __init__(self, initial=0, maximum=0, minimum=0):\n",
    "        self.value = initial\n",
    "        self.maximum = maximum\n",
    "        self.minimum = 0\n",
    "        self.cand = display_cand(initial)\n",
    "\n",
    "    def increment(self, amount=1):\n",
    "        if (self.value+amount > self.maximum):\n",
    "            return self.value\n",
    "        self.value += amount\n",
    "        return self.value\n",
    "    \n",
    "    def decrement(self, amount=1):\n",
    "        if (self.value-amount < 0):\n",
    "            return self.value\n",
    "        self.value -= amount\n",
    "        return self.value\n",
    "\n",
    "    def __iter__(self, sentinal=False):\n",
    "        return iter(self.increment, sentinal)\n",
    "    \n",
    "def display_all(cand_nr):\n",
    "    # Clear previous\n",
    "    clear_output(wait=True)\n",
    "    # Redraw\n",
    "    display(minus)\n",
    "    display(plus)\n",
    "    return display_cand(cand_nr)\n",
    "\n",
    "def btn_inc(counter, w):\n",
    "    counter.increment()  \n",
    "    counter.cand = display_all(counter.value)\n",
    "\n",
    "def btn_dec(counter, w):\n",
    "    counter.decrement()\n",
    "    counter.cand = display_all(counter.value)\n",
    "\n",
    "counter = Counter(40, maximum)\n",
    "minus = widgets.Button(description='<')\n",
    "minus.on_click(partial(btn_dec, counter))\n",
    "\n",
    "plus = widgets.Button(description='>')\n",
    "plus.on_click(partial(btn_inc, counter))\n",
    "\n",
    "display(minus)\n",
    "display(plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of candidates that match the FN[10] entity\n",
    "tp_cands = entity_to_candidates(TP[40], test_cands[0])\n",
    "\n",
    "\n",
    "# Display a candidate\n",
    "print(f\"Number of TP: {len(TP)}\")\n",
    "print(tp_cands[0])\n",
    "vis.display_candidates([tp_cands[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of candidates that match the FN[10] entity\n",
    "fn_cands = entity_to_candidates(FN[2], test_cands[0])\n",
    "\n",
    "\n",
    "# Display a candidate\n",
    "print(f\"Number of FN: {len(FN)}\")\n",
    "print(fn_cands)\n",
    "vis.display_candidates([fn_cands[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = re.compile(station_rgx, flags=re.I).search(mentions[len(mentions)-7].document.name)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
